anti_join(stop_words)
timemag_clean <- df_timemag %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
# Calculamos a frequência
?bind_rows
?str_extract
frequencia <- bind_rows(mutate(nytimes_clean, author = "NYTIMES"),
mutate(yahoo_clean, author = "YAHOO"),
mutate(timemag_clean, author = "TIME")) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(author, word) %>%
group_by(author) %>%
mutate(proportion = n/sum(n))%>%
select(-n) %>%
spread(author, proportion) %>%
gather(author, proportion, `TIME`, `NYTIMES`)
print(frequencia)
# Plot de um Correlograma para comparar os artigos
ggplot(frequencia, aes(x = proportion, y = `YAHOO`, color = abs(`YAHOO`- proportion))) +
geom_abline(color = "grey40", lty = 2) +
geom_jitter(alpha = .1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels= percent_format()) +
scale_color_gradient(limits = c(0,0.001), low = "darkslategray4", high = "gray75") +
facet_wrap(~author, ncol=2) +
theme(legend.position = "none") +
labs(y = "Yahoo", x = NULL)
# Correlação entre os artigos do Yahoo e NYTimes
cor.test(data = frequencia[frequencia$author == "NYTIMES",], ~proportion + `YAHOO`)
# Correlação entre os artigos do Yahoo e Time
cor.test(data = frequencia[frequencia$author == "TIME",], ~proportion + `YAHOO`)
# Léxicos de sentimentos
?get_sentiments
afinn <- get_sentiments("afinn")
nrc <- get_sentiments("nrc")
bing <- get_sentiments("bing")
Yes
bing <- get_sentiments("bing")
afinn <- get_sentiments("afinn")
nrc <- get_sentiments("nrc")
bing <- get_sentiments("bing")
# Método AFINN
nytimes_clean %>%
inner_join(get_sentiments("afinn")) %>%
summarise(sentiment = sum(value)) %>%
mutate(method = "AFINN")
# Método Bing
nytimes_clean %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = T)
# Método NRC
sentimentos_nytimes <- nytimes_clean %>%
inner_join(get_sentiments("nrc")) %>%
count(word, sentiment, sort = T) %>%
ungroup()
# Plot de todos os sentimentos
sentimentos_nytimes %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Sentimentos do Artigo do New York Times", x = NULL) +
coord_flip()
# Palavras mais associadas a sentimentos positivos
sentimentos_nytimes %>%
group_by(sentiment) %>%
filter(sentiment == "positive") %>%
top_n(5) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) + ggtitle("Palavras Mais Associadas a Sentimentos Positivos") +
geom_col(show.legend = FALSE, fill = "palegreen2") +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Frequência", x = NULL) +
coord_flip()
# Palavras mais associadas a sentimentos negativos
sentimentos_nytimes %>%
group_by(sentiment) %>%
filter(sentiment == "negative") %>%
top_n(5) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) + ggtitle("Palavras Mais Associadas a Sentimentos Negativos") +
geom_col(show.legend = FALSE, fill = "red3") +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Frequência", x = NULL) +
coord_flip()
# Método AFINN
yahoo_clean %>%
inner_join(get_sentiments("afinn")) %>%
summarise(sentiment = sum(value)) %>%
mutate(method = "AFINN")
# Método Bing
yahoo_clean %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = T)
# Método NRC
sentimentos_yahoo <- yahoo_clean %>%
inner_join(get_sentiments("nrc")) %>%
count(word, sentiment, sort = T) %>%
ungroup()
# Plot de todos os sentimentos
sentimentos_yahoo %>%
group_by(sentiment) %>%
top_n(8) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Sentimentos do Artigo do Yahoo Finance", x = NULL) +
coord_flip()
# Palavras mais associadas a sentimentos positivos
sentimentos_yahoo %>%
group_by(sentiment) %>%
filter(sentiment == "positive") %>%
top_n(5) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) + ggtitle("Palavras Mais Associadas a Sentimentos Positivos")+
geom_col(show.legend = FALSE, fill = "palegreen2") +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Frequência", x = NULL) +
coord_flip()
# Palavras mais associadas a sentimentos negativos
sentimentos_yahoo %>%
group_by(sentiment) %>%
filter(sentiment == "negative") %>%
top_n(5) %>%
ungroup() %>%
mutate(word=reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) + ggtitle("Palavras Mais Associadas a Sentimentos Negativos") +
geom_col(show.legend = FALSE, fill = "red3") +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Frequência", x = NULL) +
coord_flip()
# Método AFINN
timemag_clean %>%
inner_join(get_sentiments("afinn")) %>%
summarise(sentiment = sum(value)) %>%
mutate(method = "AFINN")
# Método Bing
timemag_clean %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = T)
# Método NRC
sentimentos_timemag <- timemag_clean %>%
inner_join(get_sentiments("nrc")) %>%
count(word, sentiment, sort = T) %>%
ungroup()
# Plot de todos os sentimentos
sentimentos_timemag %>%
group_by(sentiment) %>%
top_n(5) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Sentimentos do Artigo da Time Magazine", x = NULL) +
coord_flip()
# Palavras mais associadas a sentimentos positivos
sentimentos_timemag %>%
group_by(sentiment) %>%
filter(sentiment == "positive") %>%
top_n(5) %>%
ungroup() %>%
mutate(word=reorder(word, n)) %>%
ggplot(aes(word, n, fill=sentiment)) + ggtitle("Palavras Mais Associadas a Sentimentos Positivos")+
geom_col(show.legend = FALSE, fill = "palegreen2") +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Frequência", x = NULL) +
coord_flip()
# Palavras mais associadas a sentimentos negativos
sentimentos_timemag %>%
group_by(sentiment) %>%
filter(sentiment == "negative")%>%
top_n(5) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) + ggtitle("Palavras Mais Associadas a Sentimentos Negativos") +
geom_col(show.legend = FALSE, fill = "red3") +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Frequência", x = NULL) +
coord_flip()
# Combinando os artigoos
df_combinado <- bind_rows(mutate(df_nytimes, author = "Yahoo"),
mutate(df_yahoo, author = "TIME"),
mutate(df_timemag, author = "NYtimes"))
# Remoção de stop words e tokenização
df_combinado_limpo <- df_combinado %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
count(author, word, sort = TRUE) %>%
ungroup()
# Total de palavras
total_palavras <- df_combinado_limpo %>%
group_by(author) %>%
summarize(total = sum(n))
# Left join
df_combinado_limpo <- left_join(df_combinado_limpo, total_palavras)
# TF-IDF
?bind_tf_idf
df_tf_idf <- df_combinado_limpo %>%
bind_tf_idf(word, author, n)
View(df_tf_idf)
View(df_tf_idf)
# Plot das palavras mais frequentes usando TF-IDF
df_tf_idf %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(author) %>%
top_n(10) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = author)) +
geom_col(show.legend = FALSE) +
facet_wrap(~author, ncol = 2, scales = "free") +
labs(x = "Palavras Mais Frequentes", y = NULL)
# Remoção de stop words e tokenização
df_combinado2 <- df_combinado %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
count(author, word, sort = TRUE)
# Plot com NRC
df_combinado2 %>%
inner_join(get_sentiments("nrc")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("gray20", "gray80"), max.words = 200)
# Remoção de stop words e tokenização
df_combinado2 <- df_combinado %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
count(author, word, sort = TRUE)
# Plot com NRC
df_combinado2 %>%
inner_join(get_sentiments("nrc")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("gray20", "gray80"), max.words = 200)
# Plot com NRC
df_combinado2 %>%
inner_join(get_sentiments("nrc")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("gray20", "gray80"), max.words = 200)
# Plot com NRC
df_combinado2 %>%
inner_join(get_sentiments("nrc")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("gray20", "gray80"), max.words = 200)
# Plot com NRC
df_combinado2 %>%
inner_join(get_sentiments("nrc")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("gray20", "gray80"), max.words = 200)
# Plot com Bing
df_combinado2 %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("gray20", "gray80"), max.words = 200)
# Criando a Document Term Matrix para todos os artigos
doc_term_matrix <- df_combinado %>%
unnest_tokens(word, text) %>%
count(author, word) %>%
cast_dtm(author, word, n)
print(doc_term_matrix)
# Criando a Document Term Matrix para todos os artigos
doc_term_matrix <- df_combinado %>%
unnest_tokens(word, text) %>%
count(author, word) %>%
cast_dtm(author, word, n)
print(doc_term_matrix)
dtm_artigos <- df_combinado_limpo %>%
cast_dtm(author, word, n)
print(doc_term_matrix)
dtm_artigos <- df_combinado_limpo %>%
cast_dtm(author, word, n)
# LDA (Latent Dirichlet Allocation)
?LDA
modelo_lda <- LDA(dtm_artigos, k = 3, control = list(seed = 123))
modelo_lda
# Dataframe de tópicos
df_topics <- tidy(modelo_lda, matrix = "beta")
print(df_topics)
# Top termos
top_termos <- df_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
# Tópicos - Top Termos
top_termos %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
install.packages("knitr")
# Carrega bibliotecas necessárias
library(dplyr)
# Carrega bibliotecas necessárias
library(dplyr)
# Carrega bibliotecas necessárias
library(dplyr)
library(gdata)
library(ggplot2)
# Carrega bibliotecas necessárias
library(dplyr)
install.packages("dplyr")
install.packages("gdata")
# Carrega bibliotecas necessárias
library(dplyr)
# Carrega bibliotecas necessárias
library(dplyr)
install.packages("fansi")
# Carrega bibliotecas necessárias
library(dplyr)
install.packages("utf8")
# Carrega bibliotecas necessárias
library(dplyr)
install.packages("pkgconfig")
# Carrega bibliotecas necessárias
library(dplyr)
library(gdata)
library(ggplot2)
install.packages("gtable")
library(ggplot2)
install.packages("munsell")
library(ggplot2)
# Carrega bibliotecas necessárias
library(dplyr)
library(gdata)
library(ggplot2)
# Aponta para o diretório onde estão os arquivos
setwd("~/analise-series-historicas-b3")
# Carrega funções que serão utilizadas no script
source("funcoes.R")
df <- ler_arquivo("COTAHIST_A2023.TXT")
# Faz a leitura das primeiras linhas do arquivo
head(df)
# Faz a leitura das primeiras linhas do arquivo
head(df)
# Faz a leitura das primeiras linhas do arquivo
head(df)
# Faz a conversão de campos data e valores
df <- converter_campos(df)
# Resumo estatístico
summary(df$PREMAX)
# Empresas
total_registos_por_codigo <- table(df$CODNEG)
# Papéis por tipo de mercado
papeis_por_tipo <- unique(df[,c('TPMERC','CODNEG')])
table(papeis_por_tipo$TPMERC)
# Papéis por código BDI
papeis_por_bdi <- unique(df[,c('CODBDI','CODNEG')])
qtde_bdi <- data.frame(table(papeis_por_bdi$CODBDI))
COD = 'BBAS3'
dfCODNEG <- filter(df, trim(CODNEG) == COD)
# Carrega bibliotecas necessárias
library(dplyr)
library(gdata)
library(ggplot2)
# Aponta para o diretório onde estão os arquivos
setwd("~/analise-series-historicas-b3")
# Carrega funções que serão utilizadas no script
source("funcoes.R")
# Realiza o carregamento do arquivo de texto
# Os arquivos poderão ser acessados pelo link oficial da B3:
# https://www.b3.com.br/pt_br/market-data-e-indices/servicos-de-dados/market-data/historico/mercado-a-vista/series-historicas/
df <- ler_arquivo("COTAHIST_A2023.TXT")
# Faz a leitura das primeiras linhas do arquivo
head(df)
# Faz a conversão de campos data e valores
df <- converter_campos(df)
# Resumo estatístico
summary(df$PREMAX)
# Empresas
table(df$CODNEG)
# Codigo de Negociação do papel (CODNEG)
COD = 'BBAS3'
dfCODNEG <- filter(df, trim(CODNEG) == COD)
# Gera gráfico de linhas para Preço de Abertura
titulo = paste("Evolução do Preço de Abertura. Código:", COD, sep = ' ')
cor="blue"
gerar_grafico(dfCODNEG, dfCODNEG$DATAP, dfCODNEG$PREABE, titulo, cor)
install.packages("labeling")
# Gera gráfico de linhas para Preço de Abertura
titulo = paste("Evolução do Preço de Abertura. Código:", COD, sep = ' ')
cor="blue"
gerar_grafico(dfCODNEG, dfCODNEG$DATAP, dfCODNEG$PREABE, titulo, cor)
install.packages("farver")
# Carrega bibliotecas necessárias
library(dplyr)
library(gdata)
library(ggplot2)
# Aponta para o diretório onde estão os arquivos
setwd("~/analise-series-historicas-b3")
# Carrega funções que serão utilizadas no script
source("funcoes.R")
df <- ler_arquivo("COTAHIST_A2023.TXT")
# Faz a leitura das primeiras linhas do arquivo
head(df)
# Faz a conversão de campos data e valores
df <- converter_campos(df)
# Resumo estatístico
summary(df$PREMAX)
# Empresas
table(df$CODNEG)
COD = 'BBAS3'
dfCODNEG <- filter(df, trim(CODNEG) == COD)
# Gera gráfico de linhas para Preço de Abertura
titulo = paste("Evolução do Preço de Abertura. Código:", COD, sep = ' ')
cor="blue"
gerar_grafico(dfCODNEG, dfCODNEG$DATAP, dfCODNEG$PREABE, titulo, cor)
# Gera gráfico de linhas para Preço Máximo
titulo = paste("Evolução do Preço Máximo. Código:", COD, sep = ' ')
cor="green"
gerar_grafico(dfCODNEG, dfCODNEG$DATAP, dfCODNEG$PREMAX, titulo, cor)
# Gera gráfico de linhas para Preço Mínimo
titulo = paste("Evolução do Preço Mínimo Código:", COD, sep = ' ')
cor="orange"
gerar_grafico(dfCODNEG, dfCODNEG$DATAP, dfCODNEG$PREMIN, titulo, cor)
# Gera gráfico de linhas para Preço Médio
titulo = paste("Evolução do Preço Médio Código:", COD, sep = ' ')
cor="brown"
gerar_grafico(dfCODNEG, dfCODNEG$DATAP, dfCODNEG$PREMED, titulo, cor)
# Gera gráfico de linhas para Preço do último negócio
titulo = paste("Evolução do Preço do último negócio Código:", COD, sep = ' ')
cor="red"
gerar_grafico(dfCODNEG, dfCODNEG$DATAP, dfCODNEG$PREULT, titulo, cor)
# Gera gráfico de linhas para Melhor oferta de compra
titulo = paste("Evolução do Preço da Melhor Oferta de Compra Código:", COD, sep = ' ')
cor="gray"
gerar_grafico(dfCODNEG, dfCODNEG$DATAP, dfCODNEG$PREOFC, titulo, cor)
# Gera gráfico de linhas para Melhor oferta de venda
titulo = paste("Evolução do Preço da Melhor Oferta de Venda Código:", COD, sep = ' ')
cor="black"
gerar_grafico(dfCODNEG, dfCODNEG$DATAP, dfCODNEG$PREOFV, titulo, cor)
# Faz a conversão de campos data e valores
df <- converter_campos(df)
# Resumo estatístico
summary(df$PREMAX)
# Empresas
table(df$CODNEG)
COD = 'BBAS3'
dfCODNEG <- filter(df, trim(CODNEG) == COD)
fig <- dfCODNEG %>% plot_ly(x = ~DATAP, type="candlestick",
open = ~PREABE, close = ~PREULT,
high = ~PREMAX, low = ~PREMIN)
library(plotly)
# Carrega bibliotecas necessárias
library(dplyr)
library(gdata)
library(plotly)
install.packages("data.table")
install.packages("data.table")
library(plotly)
install.packages("plotly")
library(plotly)
library(quantmod)
# Resumo estatístico
summary(df$PREMAX)
# Empresas
table(df$CODNEG)
COD = 'BBAS3'
dfCODNEG <- filter(df, trim(CODNEG) == COD)
fig <- dfCODNEG %>% plot_ly(x = ~DATAP, type="candlestick",
open = ~PREABE, close = ~PREULT,
high = ~PREMAX, low = ~PREMIN)
fig <- fig %>% layout(title = "Candlestick")
fig
install.packages("ellipsis")
dfCODNEG <- filter(df, trim(CODNEG) == COD)
fig <- dfCODNEG %>% plot_ly(x = ~DATAP, type="candlestick",
open = ~PREABE, close = ~PREULT,
high = ~PREMAX, low = ~PREMIN)
fig <- fig %>% layout(title = "Candlestick")
fig
COD = 'BBAS3'
dfCODNEG <- filter(df, trim(CODNEG) == COD)
# Gera gráfico de linhas para Preço de Abertura
titulo = paste("Análise do Preço de Abertura. Código:", COD, sep = ' ')
gerar_boxplot(dfCODNEG, dfCODNEG$CODNEG, dfCODNEG$PREABE, titulo)
# Gera gráfico de linhas para Preço Máximo
titulo = paste("Análise do Preço Máximo. Código:", COD, sep = ' ')
gerar_boxplot(dfCODNEG, dfCODNEG$CODNEG, dfCODNEG$PREMAX, titulo)
# Gera gráfico de linhas para Preço Mínimo
titulo = paste("Análise do Preço Mínimo Código:", COD, sep = ' ')
gerar_boxplot(dfCODNEG, dfCODNEG$CODNEG, dfCODNEG$PREMIN, titulo)
# Gera gráfico de linhas para Preço Médio
titulo = paste("Análise do Preço Médio Código:", COD, sep = ' ')
gerar_boxplot(dfCODNEG, dfCODNEG$CODNEG, dfCODNEG$PREMED, titulo)
# Gera gráfico de linhas para Preço do último negócio
titulo = paste("Análise do Preço do último negócio Código:", COD, sep = ' ')
gerar_boxplot(dfCODNEG, dfCODNEG$CODNEG, dfCODNEG$PREULT, titulo)
# Gera gráfico de linhas para Melhor oferta de compra
titulo = paste("Análise do Preço da Melhor Oferta de Compra Código:", COD, sep = ' ')
gerar_boxplot(dfCODNEG, dfCODNEG$CODNEG, dfCODNEG$PREOFC, titulo)
# Gera gráfico de linhas para Melhor oferta de venda
titulo = paste("Análise do Preço da Melhor Oferta de Venda Código:", COD, sep = ' ')
gerar_boxplot(dfCODNEG, dfCODNEG$CODNEG, dfCODNEG$PREOFV, titulo)
# Libera memória
unlink(df)
